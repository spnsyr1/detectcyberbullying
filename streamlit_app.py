import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import gdown
import os

st.title("Deteksi Komentar Cyberbullying")

model_path = "cyberbullying_model/model.safetensors"
tokenizer_path = "cyberbullying_tokenizer"
model_dir = "cyberbullying_model"

if not os.path.exists(model_path):
    st.info("Mengunduh model...")
    os.makedirs(model_dir, exist_ok=True)
    url = "https://drive.google.com/uc?id=1Rgqp7lmibftxEe9tML9lcv6KpmAHPBe2"
    gdown.download(url, model_path, quiet=False)

@st.cache_resource(show_spinner="Memuat model...")
def load_model():
    model = AutoModelForSequenceClassification.from_pretrained(indobenchmark/indobert-base-p1)
    tokenizer = AutoTokenizer.from_pretrained(indobenchmark/indobert-base-p1)
    return tokenizer, model

tokenizer, model = load_model()

user_input = st.text_area("**Masukkan komentar:**")

if st.button("**Deteksi**") and user_input.strip():
    inputs = tokenizer(user_input, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=1)
        pred = torch.argmax(probs).item()
        confidence = probs[0][pred].item()

    label = "Cyberbullying ðŸ˜¡" if pred == 0 else "Bukan Cyberbullying ðŸ˜Š"
    st.divider()
    st.write("**Hasil Deteksi:**")
    if pred == 1:
        st.success(f"### {label} \n(**Probabilitas: {confidence:.2f}**)")
    else:
        st.warning(f"### {label} \n(**Probabilitas: {confidence:.2f}**)")
